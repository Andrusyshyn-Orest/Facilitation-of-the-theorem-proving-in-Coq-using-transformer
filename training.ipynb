{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GRus8L7m1aK9446WXPlrEO82RCS44ncz","timestamp":1711721165401}],"collapsed_sections":["9vi6XSOUTtO8","_srRfnAxr_cG"],"gpuType":"T4","authorship_tag":"ABX9TyP86T+k4OZAQmJmUm2CSonx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dcd83208f0ca4c0fbaff41694747239a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51f2c1b93a224c9ab525c90752621fad","IPY_MODEL_245110a2f4d748e793f48bc11617af56","IPY_MODEL_8589693a7d4f4b398bd598ae343cd0eb"],"layout":"IPY_MODEL_f4aedc513f9c442bbe007c880bb2601a"}},"51f2c1b93a224c9ab525c90752621fad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a74cf532d22344afbe9cb21a6439eb73","placeholder":"​","style":"IPY_MODEL_51fa62dbdd064487a0a182432f683644","value":"Download file model.safetensors: 100%"}},"245110a2f4d748e793f48bc11617af56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e3611e76f744ae8865aceaf52c009e","max":503128704,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8384338b68b244be94213ef5ad0c7280","value":503128704}},"8589693a7d4f4b398bd598ae343cd0eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8728fcbc1aed42af98c2b8ebd684742c","placeholder":"​","style":"IPY_MODEL_2ebe20f1e496489e9fd1880132d3df5e","value":" 480M/480M [01:30&lt;00:00, 775kB/s]"}},"f4aedc513f9c442bbe007c880bb2601a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a74cf532d22344afbe9cb21a6439eb73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51fa62dbdd064487a0a182432f683644":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30e3611e76f744ae8865aceaf52c009e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8384338b68b244be94213ef5ad0c7280":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8728fcbc1aed42af98c2b8ebd684742c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebe20f1e496489e9fd1880132d3df5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fc896cc8b214c72a4875413c19119b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d783a54f00e48178a221fd9cfcf5abd","IPY_MODEL_93d055520c684a3faa1ce1a78c9907f0","IPY_MODEL_b97eeb110b174f928c1fecc81f8df379"],"layout":"IPY_MODEL_16d57b8ddfe541b59e5ed284d2ff757c"}},"5d783a54f00e48178a221fd9cfcf5abd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1bf0a48c576406bb9e989486ca2f37d","placeholder":"​","style":"IPY_MODEL_a939e97fc5734dc9b81b3d2a4eb6c585","value":"Clean file model.safetensors: 100%"}},"93d055520c684a3faa1ce1a78c9907f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6037ff373589459aa0118964142f7fc9","max":503128704,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f336541208f482e84fc4c35f4456fa5","value":503128704}},"b97eeb110b174f928c1fecc81f8df379":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f209d025fa4412393db5a531dd3fff5","placeholder":"​","style":"IPY_MODEL_271d1a4ba404407988206e9c4b72c21c","value":" 480M/480M [00:44&lt;00:00, 13.3MB/s]"}},"16d57b8ddfe541b59e5ed284d2ff757c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1bf0a48c576406bb9e989486ca2f37d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a939e97fc5734dc9b81b3d2a4eb6c585":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6037ff373589459aa0118964142f7fc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f336541208f482e84fc4c35f4456fa5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f209d025fa4412393db5a531dd3fff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"271d1a4ba404407988206e9c4b72c21c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e5d21fecbb74d98b9c2d0a087bd3d55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdcff1c2f11b422a9e2cb909b7f806b6","IPY_MODEL_7d51eb5e63e948ae80a5cdf00de27ccf","IPY_MODEL_c8045402bafa435098878126a2d4e58e"],"layout":"IPY_MODEL_f2c3f2262fc3429393bdb5bc8224f021"}},"bdcff1c2f11b422a9e2cb909b7f806b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4c624c1fcad457e951d3468f1cf9c8e","placeholder":"​","style":"IPY_MODEL_91862e0c65804f618120e54fc5bd2f14","value":"100%"}},"7d51eb5e63e948ae80a5cdf00de27ccf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16db014d49dc4d1593e39a7ddec1db33","max":142,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12d3cb37f9b94f88bf5273612cd42da7","value":142}},"c8045402bafa435098878126a2d4e58e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d83d95bfa1194f62975f03e4a006647a","placeholder":"​","style":"IPY_MODEL_3f845c47d0424879acdbe9e2889f41e0","value":" 142/142 [00:00&lt;00:00, 258.27it/s]"}},"f2c3f2262fc3429393bdb5bc8224f021":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c624c1fcad457e951d3468f1cf9c8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91862e0c65804f618120e54fc5bd2f14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16db014d49dc4d1593e39a7ddec1db33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12d3cb37f9b94f88bf5273612cd42da7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d83d95bfa1194f62975f03e4a006647a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f845c47d0424879acdbe9e2889f41e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"995024240e7949019c5c467feda28114":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91c0ccf47baa45f4b74afe7314976813","IPY_MODEL_6c6918882bd24a3dadf4a2181aa03269","IPY_MODEL_5e9ca105eb5945d8bd6d395764bb20f2"],"layout":"IPY_MODEL_f7091a98d0ea436eafe15052dfbdd7be"}},"91c0ccf47baa45f4b74afe7314976813":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2065614efaa146a69a5dbd07212d642b","placeholder":"​","style":"IPY_MODEL_93be5c583ea34d568eabbcfe4e3a9a3a","value":"100%"}},"6c6918882bd24a3dadf4a2181aa03269":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7a2e0ab524a4d538926879c5e7133b6","max":142,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd080e8050de4b0d890a4484fe113223","value":142}},"5e9ca105eb5945d8bd6d395764bb20f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78a4ca3f7bb347f1ae98ab3bffdb74de","placeholder":"​","style":"IPY_MODEL_4236bbeba3ec4b70a635f48ca3cb6897","value":" 142/142 [02:18&lt;00:00,  1.72it/s]"}},"f7091a98d0ea436eafe15052dfbdd7be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2065614efaa146a69a5dbd07212d642b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93be5c583ea34d568eabbcfe4e3a9a3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7a2e0ab524a4d538926879c5e7133b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd080e8050de4b0d890a4484fe113223":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78a4ca3f7bb347f1ae98ab3bffdb74de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4236bbeba3ec4b70a635f48ca3cb6897":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3be0647a47b2427b96cb35b0738565c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ff8f8ca78e041b7b00c4e35999d7060","IPY_MODEL_d40cc97d41cd4605a73c59776ef518ce","IPY_MODEL_5002582ed9a744e6b404d4d00cbf7580"],"layout":"IPY_MODEL_4c8f1dc9fdb744adbb90415588c2a59f"}},"7ff8f8ca78e041b7b00c4e35999d7060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22dccf342698488ba5ad1d1426697974","placeholder":"​","style":"IPY_MODEL_1064fc1a863d4d23b222f1bb231846d1","value":" 36%"}},"d40cc97d41cd4605a73c59776ef518ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a27c872255f46cd99c0e82d024d545f","max":142,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03694f1698bb432393c7af4a2fad9f52","value":51}},"5002582ed9a744e6b404d4d00cbf7580":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf3bb3bc5c941b98f8c01a2238c9800","placeholder":"​","style":"IPY_MODEL_b69d353af293494b994752f3138fe6ce","value":" 51/142 [01:26&lt;00:53,  1.71it/s]"}},"4c8f1dc9fdb744adbb90415588c2a59f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22dccf342698488ba5ad1d1426697974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1064fc1a863d4d23b222f1bb231846d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a27c872255f46cd99c0e82d024d545f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03694f1698bb432393c7af4a2fad9f52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baf3bb3bc5c941b98f8c01a2238c9800":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b69d353af293494b994752f3138fe6ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TlOfuAT4e-xu"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install accelerate\n","!apt install git-lfs"]},{"cell_type":"code","source":["import torch\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data.dataloader import DataLoader\n","from torch.optim import AdamW\n","from torch.utils.tensorboard import SummaryWriter\n","%load_ext tensorboard\n","\n","from huggingface_hub import notebook_login, Repository\n","from datasets import load_dataset, DatasetDict, Dataset\n","from accelerate import Accelerator\n","from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig, pipeline, get_scheduler\n","from transformers.keras_callbacks import PushToHubCallback\n","\n","import re\n","import json\n","import os\n","from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","from google.colab import drive"],"metadata":{"id":"J6UDRGWQg4UD","executionInfo":{"status":"ok","timestamp":1711709595820,"user_tz":-120,"elapsed":10829,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### TRAINING\n"],"metadata":{"id":"iy7X6uix8Odn"}},{"cell_type":"markdown","source":["#### HYPER PARAMS, GLOBAL VARS, FUNCTIONS"],"metadata":{"id":"PbZLtjmyh0Tb"}},{"cell_type":"code","source":["# HYPER PARAMETERS\n","context_length                 = 1024\n","train_batch_size               = 4\n","eval_batch_size                = 4\n","weight_decay                   = 0.1\n","lr                             = 5e-4\n","lr_scheduler_type              = \"linear\"    # \"linear\" | \"cosine\" | \"constant\"\n","num_warmup_steps               = 50\n","gradient_accumulation_steps    = 8\n","gradient_checkpointing         = False\n","eval_steps                     = 50 // gradient_accumulation_steps\n","num_train_epochs               = 5\n","mixed_precision                = \"fp16\"\n","\n","#GLOBAL VARS\n","have_git_write_access          = True                              # set to True if you need to commit changes\n","user_email                     = \"orest.andrusyshyn@ucu.edu.ua\"    # only needed if above have_git_write_access == True\n","user_name                      = \"Orest Andrusyshyn\"               # only needed if above have_git_write_access == True\n","\n","drive_mounted                  = True\n","drive_mounted_path             = '/content/gdrive/'    # only needed if drive_mounted == True\n","save_json_logs                 = True                  # set to True to save training results into json file (drive_train_res_path)\n","drive_train_res_path           = drive_mounted_path + 'My Drive/UCU/diploma/progress_notes/training_results/second_training/testing_algo1.json'    # only needed if save_json_logs == True\n","save_tensorboard_logs          = True                  # set to True to save training results into tensorboard run (tensorboard_run_path)\n","tensorboard_run_path           = drive_mounted_path + 'My Drive/UCU/diploma/progress_notes/training_results/tensorboard_runs/testing_algo'                   # only needed if save_tensorboard_logs == True\n","\n","data_archived                  = True    # set to True if you need to unarchive the data\n","raw_train_archive              = \"./pretrain_dataset_train.json.gz\"         # only needed if data_archived == True\n","raw_valid_archive              = \"./pretrain_dataset_validation.json.gz\"    # only needed if data_archived == True\n","raw_train_json                 = \"./pretrain_dataset_train.json\"            # only needed if data_archived == False\n","raw_valid_json                 = \"./pretrain_dataset_validation.json\"       # only needed if data_archived == False\n","\n","tokenizer_repo_name            = \"Andrusyshyn/gpt2-coq-tokenizer\"\n","tokenizer_commit_hash          = \"90c3858771e6120dfc8eab7a6754295964e8d8c3\"\n","\n","init_model                     = \"gpt2\"                                                   # base model Hugging Face name\n","model_repo_name                = \"Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train\"\n","model_output_dir               = \"./gpt2-pretrained-for-coq-pt-custom-train-local\"        # local dir to save the model\n","\n","push_to_hub                    = True                 # set to True to push the model\n","run_name                       = \"testing_algo\"    # branch name (only needed if push_to_hub == True)\n","\n","partially_trained              = True                                         # set to True to continue model training from specific commit hash (model_commit_hash)\n","model_commit_hash              = \"91aac830c5ff8417d8bf389eea271a9d3dabab9c\"    # only needed if partially_trained == True\n","previously_completed_steps     = 18                                          # only needed if partially_trained == True\n","previous_global_steps          = 144                                         # only needed if partially_trained == True\n","previous_step                  = 1                                          # only needed if partially_trained == True\n","stopped_epoch                  = 1                                             # only needed if partially_trained == True\n","\n","torch.manual_seed(7)"],"metadata":{"id":"7VRZhQTKZaSs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711709818028,"user_tz":-120,"elapsed":502,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"bb3c8614-21de-48e1-aac9-0e63bc2c5f17"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7e9cfc976250>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# CUSTOM LOSS FUNCTION\n","def custom_loss(inputs, logits):\n","    # inputs [batch_size X cl]\n","    # logits [btach_size X cl X vocab_size]\n","    # Our labels start from second sequence token because first one does not have preceding token.\n","    # We drop last logit because last sequence token does not have subsequent token, so no label to compare\n","    shifted_labels = inputs[..., 1:].contiguous()\n","    shifted_logits = logits[..., :-1, :].contiguous()\n","\n","    loss_func = CrossEntropyLoss(reduce=False)\n","    # loss [batch_size * (cl-1)] = loss_fct([batch_size * (cl-1) X vocab_size], [batch_size * (cl-1)])\n","    loss = loss_func(shifted_logits.view(-1, shifted_logits.size(-1)), shifted_labels.view(-1))\n","    # loss_per_sample [batch_size]\n","    loss_per_sequence = loss.view(shifted_logits.size(0), shifted_logits.size(1)).mean(axis=1)\n","    return loss_per_sequence.mean()"],"metadata":{"id":"dVnxDLITeUwq","executionInfo":{"status":"ok","timestamp":1711709618451,"user_tz":-120,"elapsed":506,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# PARAMETERS FOR WEIGHT DECAY\n","def get_wd_parameters(model, no_decay=[\"bias\", r\"ln_.{1,2}\\.weight\"]):\n","    wd_params = []\n","    nwd_params = []\n","    for name, params in model.named_parameters():\n","        if any(re.search(nd_reg, name) for nd_reg in no_decay):\n","            nwd_params.append(params)\n","        else:\n","            wd_params.append(params)\n","    return [\n","        {\"params\": wd_params,  \"weight_decay\": weight_decay},\n","        {\"params\": nwd_params, \"weight_decay\": 0.0},\n","    ]"],"metadata":{"id":"s4G7PyR8eaZV","executionInfo":{"status":"ok","timestamp":1711709619471,"user_tz":-120,"elapsed":2,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# TOKENIZE RAW DATASETS\n","def get_tokenized_dataset(p_raw_dataset, p_context_length, p_tokenizer):\n","    concatenated_tokenized_samples = []\n","    for sample in p_raw_dataset:\n","        tokenized_sample = p_tokenizer(sample[\"content\"], truncation=False)[\"input_ids\"]\n","        concatenated_tokenized_samples.extend(tokenized_sample + [p_tokenizer.eos_token_id])\n","    tokenized_dataset_list = []\n","    for i in range(0, len(concatenated_tokenized_samples), p_context_length):\n","        input_ids = concatenated_tokenized_samples[i : i + p_context_length]\n","        if len(input_ids) == p_context_length:\n","            tokenized_dataset_list.append(torch.tensor(input_ids))\n","\n","    return Dataset.from_dict({\"input_ids\": tokenized_dataset_list})"],"metadata":{"id":"ZHTy8qSxLjjJ","executionInfo":{"status":"ok","timestamp":1711709621350,"user_tz":-120,"elapsed":2,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# SAVING TRAINING RESULTS TO THE JSON FILE\n","def save_results(filepath:str, split: str, results: dict):\n","    \"\"\"\n","    {\n","        \"hyperparams\": {},\n","        \"train\": [\n","            results1,\n","            results2,\n","            ...\n","        ],\n","        \"valid\": [\n","            results1,\n","            results2,\n","            ...\n","        ]\n","    }\n","    \"\"\"\n","    if not save_json_logs:\n","        return\n","    if split not in {\"train\", \"valid\"}:\n","        print(\"ERROR: INVALID SPLIT\")\n","        return\n","    _run_name = run_name\n","    if not push_to_hub:\n","        _run_name = \"\"\n","    _tensorboard_run_path = tensorboard_run_path\n","    if not save_tensorboard_logs:\n","        _tensorboard_run_path = \"\"\n","    hyperparams_dict = {\n","        \"context_length\"                 : context_length,\n","        \"train_batch_size\"               : train_batch_size,\n","        \"eval_batch_size\"                : eval_batch_size,\n","        \"weight_decay\"                   : weight_decay,\n","        \"lr\"                             : lr,\n","        \"lr_scheduler_type\"              : lr_scheduler_type,\n","        \"num_warmup_steps\"               : num_warmup_steps,\n","        \"gradient_accumulation_steps\"    : gradient_accumulation_steps,\n","        \"gradient_checkpointing\"         : gradient_checkpointing,\n","        \"eval_steps\"                     : eval_steps,\n","        \"num_train_epochs\"               : num_train_epochs,\n","        \"mixed_precision\"                : mixed_precision,\n","        \"tokenizer_repo_name\"            : tokenizer_repo_name,\n","        \"tokenizer_commit_hash\"          : tokenizer_commit_hash,\n","        \"init_model\"                     : init_model,\n","        \"model_repo_name\"                : model_repo_name,\n","        \"run_name\"                       : _run_name,\n","        \"drive_train_res_path\"           : drive_train_res_path,\n","        \"tensorboard_run_path\"           : _tensorboard_run_path,\n","    }\n","    json_data = {\"train\": [], \"valid\": []}\n","    if os.path.exists(filepath):\n","        with open(filepath, 'r') as json_file:\n","            json_data = json.load(json_file)\n","    json_data[\"hyperparams\"] = hyperparams_dict\n","    json_data[split].append(results)\n","    with open(filepath, 'w') as json_file:\n","        json.dump(json_data, json_file, indent=4)"],"metadata":{"id":"3dJLZFnz2StA","executionInfo":{"status":"ok","timestamp":1711709622936,"user_tz":-120,"elapsed":1,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# TENSORBOARD VISUALISATION\n","def add_to_tensorboard(json_filepath, tensorboard_run_path):\n","    if not save_tensorboard_logs:\n","        return\n","    if not os.path.exists(json_filepath):\n","        print(\"ERROR: json_filepath DOES NOT EXIST\")\n","        return\n","    with open(json_filepath, mode=\"r\") as json_file:\n","        json_data = json.load(json_file)\n","        one_step_tokens = json_data[\"hyperparams\"][\"train_batch_size\"] * json_data[\"hyperparams\"][\"gradient_accumulation_steps\"] * json_data[\"hyperparams\"][\"context_length\"]\n","        writer = SummaryWriter(tensorboard_run_path)\n","        prev_comleted_steps = json_data[\"train\"][0][\"competed_steps\"]\n","        prev_lr = json_data[\"train\"][0][\"lr\"][0]\n","        train_losses = []\n","        cs = 0\n","        for entry in json_data[\"train\"]:\n","            cs = entry[\"competed_steps\"]\n","            if cs == prev_comleted_steps:\n","                train_losses.append(entry[\"loss/train\"])\n","                continue\n","            else:\n","                writer.add_scalar(\"Loss/Train\", sum(train_losses)/len(train_losses), prev_comleted_steps * one_step_tokens)\n","                writer.add_scalar(\"Learning Rate\", prev_lr, prev_comleted_steps * one_step_tokens)\n","                train_losses = [entry[\"loss/train\"]]\n","                prev_comleted_steps = cs\n","                prev_lr = entry[\"lr\"][0]\n","        writer.add_scalar(\"Loss/Train\", sum(train_losses)/len(train_losses), cs * one_step_tokens)\n","        writer.add_scalar(\"Learning Rate\", prev_lr, cs * one_step_tokens)\n","\n","        for entry in json_data[\"valid\"]:\n","            cs = entry[\"competed_steps\"]\n","            writer.add_scalar(\"Loss/Eval\", entry[\"loss/eval\"], cs * one_step_tokens)\n","            writer.add_scalar(\"Perplexity/Eval\", entry[\"perplexity\"], cs * one_step_tokens)\n","        writer.close()"],"metadata":{"id":"negAfxKOtdOA","executionInfo":{"status":"ok","timestamp":1711709624909,"user_tz":-120,"elapsed":2,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["#### CONFIGURING"],"metadata":{"id":"1avaSDQZ_-M2"}},{"cell_type":"code","source":["# MOUNTING DRIVE FOR SAVING LOGS\n","if drive_mounted:\n","    drive.mount(drive_mounted_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mp6KpOhAC2T","executionInfo":{"status":"ok","timestamp":1711709628904,"user_tz":-120,"elapsed":2036,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"1537973c-1d05-4a0c-c2c8-d66963fc82fe"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# CONFIGURING GIT CREDENTIALS\n","if have_git_write_access:\n","    !git config --global user.email \"{user_email}\"\n","    !git config --global user.name \"{user_name}\"\n","\n","# To set Hugging Face token (for writing access) create HF_TOKEN secret in Google Collab or use notebook_login()"],"metadata":{"id":"5Z8pOm7N_hql","executionInfo":{"status":"ok","timestamp":1711709630768,"user_tz":-120,"elapsed":4,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# CONFIGURING GIT DIRECTORIES\n","if push_to_hub:\n","    repo = Repository(model_output_dir, clone_from=model_repo_name)\n","    repo.git_checkout(run_name, create_branch_ok=True)"],"metadata":{"id":"xxYRTff8gOzr","colab":{"base_uri":"https://localhost:8080/","height":292,"referenced_widgets":["dcd83208f0ca4c0fbaff41694747239a","51f2c1b93a224c9ab525c90752621fad","245110a2f4d748e793f48bc11617af56","8589693a7d4f4b398bd598ae343cd0eb","f4aedc513f9c442bbe007c880bb2601a","a74cf532d22344afbe9cb21a6439eb73","51fa62dbdd064487a0a182432f683644","30e3611e76f744ae8865aceaf52c009e","8384338b68b244be94213ef5ad0c7280","8728fcbc1aed42af98c2b8ebd684742c","2ebe20f1e496489e9fd1880132d3df5e","5fc896cc8b214c72a4875413c19119b9","5d783a54f00e48178a221fd9cfcf5abd","93d055520c684a3faa1ce1a78c9907f0","b97eeb110b174f928c1fecc81f8df379","16d57b8ddfe541b59e5ed284d2ff757c","a1bf0a48c576406bb9e989486ca2f37d","a939e97fc5734dc9b81b3d2a4eb6c585","6037ff373589459aa0118964142f7fc9","5f336541208f482e84fc4c35f4456fa5","0f209d025fa4412393db5a531dd3fff5","271d1a4ba404407988206e9c4b72c21c"]},"executionInfo":{"status":"ok","timestamp":1711709741200,"user_tz":-120,"elapsed":107638,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"58583037-3236-4895-aac0-45583b11f37a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n","For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n","  warnings.warn(warning_message, FutureWarning)\n","Cloning https://huggingface.co/Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train into local empty directory.\n","WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train into local empty directory.\n"]},{"output_type":"display_data","data":{"text/plain":["Download file model.safetensors:   0%|          | 8.00k/480M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd83208f0ca4c0fbaff41694747239a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Clean file model.safetensors:   0%|          | 1.00k/480M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc896cc8b214c72a4875413c19119b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checked out testing_algo from testing_algo.\n","WARNING:huggingface_hub.repository:Checked out testing_algo from testing_algo.\n","Branch 'testing_algo' set up to track remote branch 'testing_algo' from 'origin'.\n","\n","WARNING:huggingface_hub.repository:Branch 'testing_algo' set up to track remote branch 'testing_algo' from 'origin'.\n","\n"]}]},{"cell_type":"markdown","source":["#### DATASETS"],"metadata":{"id":"QCzfmzzIgSXC"}},{"cell_type":"code","source":["# UNPACK DATASETS\n","if data_archived:\n","    !gzip -dkv \"{raw_train_archive}\"\n","    !gzip -dkv \"{raw_valid_archive}\"\n","    raw_train_json = raw_train_archive[:-3]\n","    raw_valid_json = raw_valid_archive[:-3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyIeffM-P9if","executionInfo":{"status":"ok","timestamp":1711709787093,"user_tz":-120,"elapsed":45897,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"18706f09-60ae-4ab1-c536-743473d07606"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["gzip: ./pretrain_dataset_train.json already exists; do you wish to overwrite (y or n)? ^C\n","gzip: ./pretrain_dataset_validation.json already exists; do you wish to overwrite (y or n)? ^C\n"]}]},{"cell_type":"code","source":["# LOAD DATASETS\n","data_files = {\"train\": raw_train_json, \"validation\": raw_valid_json}\n","raw_datasets = load_dataset(\"json\", data_files=data_files, field=\"data\")\n","print(raw_datasets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtwDIj4TP-NP","executionInfo":{"status":"ok","timestamp":1711709788045,"user_tz":-120,"elapsed":954,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"59bf0a38-3fe3-40fd-e528-d2bbee059fba"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['filepath', 'content'],\n","        num_rows: 5969\n","    })\n","    validation: Dataset({\n","        features: ['filepath', 'content'],\n","        num_rows: 663\n","    })\n","})\n"]}]},{"cell_type":"code","source":["# DEBUG CODE (taking few samples from whole DatasetDict)\n","train_debug = raw_datasets[\"train\"][:200]\n","valid_debug = raw_datasets[\"validation\"][:50]\n","train_debug_dataset = Dataset.from_dict(train_debug)\n","valid_debug_dataset = Dataset.from_dict(valid_debug)\n","raw_datasets = DatasetDict({\"train\": train_debug_dataset, \"validation\": valid_debug_dataset})\n","print(raw_datasets)"],"metadata":{"id":"m3xbNM7ajC5A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711709788046,"user_tz":-120,"elapsed":5,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"76e5562d-0cc7-44b5-9ada-5eb3495c7377"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['filepath', 'content'],\n","        num_rows: 200\n","    })\n","    validation: Dataset({\n","        features: ['filepath', 'content'],\n","        num_rows: 50\n","    })\n","})\n"]}]},{"cell_type":"code","source":["# LOADING TOKENIZER\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_repo_name, revision=tokenizer_commit_hash)\n","print(\"tokenizer vocab size: \", len(tokenizer))\n","# TOKENIZE RAW DATASETS\n","train_dataset = get_tokenized_dataset(raw_datasets[\"train\"],      context_length, tokenizer)\n","valid_dataset = get_tokenized_dataset(raw_datasets[\"validation\"], context_length, tokenizer)\n","train_dataset.set_format(\"torch\")\n","valid_dataset.set_format(\"torch\")\n","\n","# CREATE DATALOADERS\n","train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=eval_batch_size)\n","print(train_dataset)\n","print(valid_dataset)\n","print(\"len(train_dataloader): \", len(train_dataloader))\n","print(\"len(valid_dataloader): \", len(valid_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBqU_TnKQBiX","executionInfo":{"status":"ok","timestamp":1711709790639,"user_tz":-120,"elapsed":2596,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"6d25b8fb-fd31-449d-8934-7f266acac1d6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (5858 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["tokenizer vocab size:  50000\n","Dataset({\n","    features: ['input_ids'],\n","    num_rows: 568\n","})\n","Dataset({\n","    features: ['input_ids'],\n","    num_rows: 151\n","})\n","len(train_dataloader):  142\n","len(valid_dataloader):  38\n"]}]},{"cell_type":"markdown","source":["#### CONFIGURING MODEL AND TRAINING"],"metadata":{"id":"uozaVBJNiCFw"}},{"cell_type":"code","source":["# CONFIGURING MODEL\n","model = None\n","if partially_trained:\n","    print(\"Loading partially trained model\")\n","    model = GPT2LMHeadModel.from_pretrained(model_repo_name, revision=model_commit_hash)\n","else:\n","    print(\"Training from scratch\")\n","    config = AutoConfig.from_pretrained(\n","        init_model,\n","        vocab_size=len(tokenizer),\n","        n_ctx=context_length,\n","        bos_token_id=tokenizer.bos_token_id,\n","        eos_token_id=tokenizer.eos_token_id,\n","    )\n","    model = GPT2LMHeadModel(config)\n","print()\n","if gradient_checkpointing:\n","    model.gradient_checkpointing_enable()\n","\n","optimizer = AdamW(get_wd_parameters(model), lr=lr)\n","accelerator = Accelerator(mixed_precision=mixed_precision)\n","model, optimizer, train_dataloader, valid_dataloader = accelerator.prepare(\n","    model, optimizer, train_dataloader, valid_dataloader\n",")\n","\n","num_steps_per_epoch = len(train_dataloader)\n","print(\"Num steps per epoch: \", num_steps_per_epoch)\n","num_training_completed_steps = (num_train_epochs * num_steps_per_epoch) // gradient_accumulation_steps\n","if ((num_train_epochs * num_steps_per_epoch) % gradient_accumulation_steps != 0):\n","    num_training_completed_steps += 1\n","print(\"Num optimizer steps: \", num_training_completed_steps)\n","\n","\n","lr_scheduler = get_scheduler(\n","    name=\"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=num_warmup_steps,\n","    num_training_steps=num_training_completed_steps\n",")\n","\n","if partially_trained:\n","    with torch.no_grad():\n","        for _ in range(previously_completed_steps):\n","            lr_scheduler.step()\n","\n","print()\n","print(f\"Model size:                                        {model.num_parameters()}\")\n","print(f\"Model size (only trainable params):                {model.num_parameters(only_trainable=True)}\")\n","print(f\"Model size (only trainable non-embeddings params): {model.num_parameters(only_trainable=True, exclude_embeddings=True)}\")"],"metadata":{"id":"nxQPSwfzN7IQ","executionInfo":{"status":"ok","timestamp":1711709834942,"user_tz":-120,"elapsed":723,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# EVALUATION FUNCTION\n","def evaluate():\n","    torch.cuda.empty_cache()\n","\n","    model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for step, batch in enumerate(valid_dataloader):\n","            with torch.no_grad():\n","                logits = model(batch[\"input_ids\"]).logits\n","                loss = custom_loss(batch[\"input_ids\"], logits)\n","                losses.append(loss.item())\n","    loss = torch.mean(torch.Tensor(losses))\n","    try:\n","        perplexity = torch.exp(loss)\n","    except OverflowError:\n","        perplexity = float(\"inf\")\n","\n","    torch.cuda.empty_cache()\n","    return loss.item(), perplexity.item()"],"metadata":{"id":"hK4sg5C3eybv","executionInfo":{"status":"ok","timestamp":1711709865864,"user_tz":-120,"elapsed":519,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nzymk9udYzpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAINING LOOP\n","model.train()\n","completed_steps = 0\n","global_steps = 0\n","if partially_trained:\n","    completed_steps = previously_completed_steps\n","    global_steps = previous_global_steps\n","for epoch in range(num_train_epochs):\n","    for step, batch in tqdm(\n","        enumerate(train_dataloader, start=0), total=num_steps_per_epoch\n","    ):\n","        if partially_trained and ((epoch<stopped_epoch) or ((epoch==stopped_epoch) and (step <= previous_step))):\n","            continue\n","\n","        logits = model(batch[\"input_ids\"]).logits\n","        loss = custom_loss(batch[\"input_ids\"], logits)\n","################################################################################\n","        log_train = {\n","                \"loss/train\": loss.item(),\n","                \"completed_steps\": completed_steps,\n","                \"lr\": lr_scheduler.get_lr(),\n","                \"global_steps\" : global_steps,\n","                \"epoch\": epoch,\n","                \"steps\": step,\n","        }\n","        accelerator.print(log_train)\n","        save_results(drive_train_res_path, \"train\", log_train)\n","################################################################################\n","        loss = loss / gradient_accumulation_steps\n","        accelerator.backward(loss)\n","        global_steps += 1\n","################################################################################\n","        if global_steps % gradient_accumulation_steps == 0:\n","            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","            completed_steps += 1\n","        if (global_steps % (eval_steps * gradient_accumulation_steps)) == 0:\n","            eval_loss, perplexity = evaluate()\n","            log_eval = {\n","                    \"loss/eval\": eval_loss,\n","                    \"perplexity\": perplexity,\n","                    \"completed_steps\": completed_steps,\n","                    \"lr\": lr_scheduler.get_lr(),\n","                    \"global_steps\" : global_steps,\n","                    \"epoch\": epoch,\n","                    \"steps\": step,\n","                    \"loss/train\": loss.item() * gradient_accumulation_steps,\n","            }\n","            accelerator.print(log_eval)\n","            save_results(drive_train_res_path, \"valid\", log_eval)\n","            accelerator.wait_for_everyone()\n","            unwrapped_model = accelerator.unwrap_model(model)\n","            unwrapped_model.save_pretrained(model_output_dir, save_function=accelerator.save)\n","            tokenizer.save_pretrained(model_output_dir)\n","            if accelerator.is_main_process:\n","                if push_to_hub:\n","                    repo.push_to_hub(\n","                        commit_message=f\"Training in progress: completed_steps {completed_steps}; global_steps {global_steps};\\\n","                                         epoch {epoch}; steps {step}; lr {lr_scheduler.get_lr()};\\\n","                                         loss/eval {eval_loss}; perplexity {perplexity}; loss/train {loss.item() * gradient_accumulation_steps}\",\n","                        blocking=False\n","                    )\n","            model.train()\n","\n","################################################################################\n","################################################################################\n","################################################################################\n","\n","#GRADIENT UPDATE (In case (global_steps % gradient_accumulation_steps != 0)\n","last_eval_log_train_loss = 0\n","if (global_steps % gradient_accumulation_steps != 0):\n","    for step, batch in tqdm(\n","        enumerate(train_dataloader, start=0), total=(gradient_accumulation_steps - (global_steps % gradient_accumulation_steps)) - 1    # -1 here is purely for better visualisation of tqdm progress bar\n","    ):\n","        logits = model(batch[\"input_ids\"]).logits\n","        loss = custom_loss(batch[\"input_ids\"], logits)\n","        last_eval_log_train_loss = loss.item()\n","        log_train = {\n","                \"loss/train\": loss.item(),\n","                \"completed_steps\": completed_steps,\n","                \"lr\": lr_scheduler.get_lr(),\n","                \"global_steps\" : global_steps,\n","                \"epoch\": epoch,\n","                \"steps\": step + (num_train_epochs * num_steps_per_epoch),\n","        }\n","        accelerator.print(log_train)\n","        save_results(drive_train_res_path, \"train\", log_train)\n","        loss = loss / gradient_accumulation_steps\n","        accelerator.backward(loss)\n","        global_steps += 1\n","        if global_steps % gradient_accumulation_steps == 0:\n","            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","            completed_steps += 1\n","            break\n","\n","################################################################################\n","################################################################################\n","################################################################################\n","\n","# FINAL EVALUATE AND SAVE\n","additional_steps = 0\n","if (global_steps % gradient_accumulation_steps != 0):\n","    additional_steps = gradient_accumulation_steps - (global_steps % gradient_accumulation_steps)\n","with torch.no_grad():\n","    last_train_loss = 0\n","    for batch in train_dataloader:\n","        logits = model(batch[\"input_ids\"]).logits\n","        loss = custom_loss(batch[\"input_ids\"], logits)\n","        last_train_loss = loss.item()\n","        break\n","eval_loss, perplexity = evaluate()\n","log_eval = {\n","        \"loss/eval\": eval_loss,\n","        \"perplexity\": perplexity,\n","        \"completed_steps\": completed_steps,\n","        \"lr\": lr_scheduler.get_lr(),\n","        \"global_steps\" : global_steps,\n","        \"epoch\": epoch,\n","        \"steps\": (num_train_epochs * num_steps_per_epoch) + additional_steps - 1,\n","        \"loss/train\": last_eval_log_train_loss,\n","}\n","accelerator.print(log_eval)\n","log_train = {\n","        \"loss/train\": last_train_loss,\n","        \"completed_steps\": completed_steps,\n","        \"lr\": lr_scheduler.get_lr(),\n","        \"global_steps\" : global_steps,\n","        \"epoch\": epoch,\n","        \"steps\": (num_train_epochs * num_steps_per_epoch) + additional_steps,\n","}\n","save_results(drive_train_res_path, \"train\", log_train)\n","save_results(drive_train_res_path, \"valid\", log_eval)\n","accelerator.wait_for_everyone()\n","unwrapped_model = accelerator.unwrap_model(model)\n","unwrapped_model.save_pretrained(model_output_dir, save_function=accelerator.save)\n","tokenizer.save_pretrained(model_output_dir)\n","if accelerator.is_main_process:\n","    if push_to_hub:\n","        repo.push_to_hub(\n","            commit_message=f\"Final model: completed_steps {completed_steps}; global_steps {global_steps};\\\n","                             epoch {epoch}; steps {(num_train_epochs * num_steps_per_epoch) + additional_steps - 1}; lr {lr_scheduler.get_lr()};\\\n","                             loss/eval {eval_loss}; perplexity {perplexity}; loss/train {last_eval_log_train_loss}\",\n","            blocking=False\n","        )\n","model.train()\n","\n","torch.cuda.empty_cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2e5d21fecbb74d98b9c2d0a087bd3d55","bdcff1c2f11b422a9e2cb909b7f806b6","7d51eb5e63e948ae80a5cdf00de27ccf","c8045402bafa435098878126a2d4e58e","f2c3f2262fc3429393bdb5bc8224f021","b4c624c1fcad457e951d3468f1cf9c8e","91862e0c65804f618120e54fc5bd2f14","16db014d49dc4d1593e39a7ddec1db33","12d3cb37f9b94f88bf5273612cd42da7","d83d95bfa1194f62975f03e4a006647a","3f845c47d0424879acdbe9e2889f41e0","995024240e7949019c5c467feda28114","91c0ccf47baa45f4b74afe7314976813","6c6918882bd24a3dadf4a2181aa03269","5e9ca105eb5945d8bd6d395764bb20f2","f7091a98d0ea436eafe15052dfbdd7be","2065614efaa146a69a5dbd07212d642b","93be5c583ea34d568eabbcfe4e3a9a3a","a7a2e0ab524a4d538926879c5e7133b6","fd080e8050de4b0d890a4484fe113223","78a4ca3f7bb347f1ae98ab3bffdb74de","4236bbeba3ec4b70a635f48ca3cb6897","3be0647a47b2427b96cb35b0738565c6","7ff8f8ca78e041b7b00c4e35999d7060","d40cc97d41cd4605a73c59776ef518ce","5002582ed9a744e6b404d4d00cbf7580","4c8f1dc9fdb744adbb90415588c2a59f","22dccf342698488ba5ad1d1426697974","1064fc1a863d4d23b222f1bb231846d1","7a27c872255f46cd99c0e82d024d545f","03694f1698bb432393c7af4a2fad9f52","baf3bb3bc5c941b98f8c01a2238c9800","b69d353af293494b994752f3138fe6ce"]},"id":"CMxa25rIPbAi","outputId":"0061f5a8-d522-487c-bb54-72965eaa1e54","executionInfo":{"status":"error","timestamp":1711710098411,"user_tz":-120,"elapsed":226100,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}}},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/142 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e5d21fecbb74d98b9c2d0a087bd3d55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/142 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"995024240e7949019c5c467feda28114"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["{'loss/train': 1.0958545207977295, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 144, 'epoch': 1, 'steps': 2}\n","{'loss/train': 1.430997610092163, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 145, 'epoch': 1, 'steps': 3}\n","{'loss/train': 1.0095056295394897, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 146, 'epoch': 1, 'steps': 4}\n","{'loss/train': 1.1447408199310303, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 147, 'epoch': 1, 'steps': 5}\n","{'loss/train': 1.4378679990768433, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 148, 'epoch': 1, 'steps': 6}\n","{'loss/train': 1.367504358291626, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 149, 'epoch': 1, 'steps': 7}\n","{'loss/train': 1.5254594087600708, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 150, 'epoch': 1, 'steps': 8}\n","{'loss/train': 0.9380818605422974, 'completed_steps': 18, 'lr': [0.00017999999999999998, 0.00017999999999999998], 'global_steps': 151, 'epoch': 1, 'steps': 9}\n","{'loss/train': 1.0659217834472656, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 152, 'epoch': 1, 'steps': 10}\n","{'loss/train': 1.0067886114120483, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 153, 'epoch': 1, 'steps': 11}\n","{'loss/train': 1.1114726066589355, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 154, 'epoch': 1, 'steps': 12}\n","{'loss/train': 1.1200511455535889, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 155, 'epoch': 1, 'steps': 13}\n","{'loss/train': 0.9907076954841614, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 156, 'epoch': 1, 'steps': 14}\n","{'loss/train': 1.830597162246704, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 157, 'epoch': 1, 'steps': 15}\n","{'loss/train': 1.1651256084442139, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 158, 'epoch': 1, 'steps': 16}\n","{'loss/train': 1.184767484664917, 'completed_steps': 19, 'lr': [0.00017746478873239435, 0.00017746478873239435], 'global_steps': 159, 'epoch': 1, 'steps': 17}\n","{'loss/train': 1.4903438091278076, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 160, 'epoch': 1, 'steps': 18}\n","{'loss/train': 1.2341289520263672, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 161, 'epoch': 1, 'steps': 19}\n","{'loss/train': 1.1997287273406982, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 162, 'epoch': 1, 'steps': 20}\n","{'loss/train': 1.4036749601364136, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 163, 'epoch': 1, 'steps': 21}\n","{'loss/train': 1.1929397583007812, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 164, 'epoch': 1, 'steps': 22}\n","{'loss/train': 1.273314356803894, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 165, 'epoch': 1, 'steps': 23}\n","{'loss/train': 1.053062915802002, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 166, 'epoch': 1, 'steps': 24}\n","{'loss/train': 1.550766110420227, 'completed_steps': 20, 'lr': [0.00017492957746478873, 0.00017492957746478873], 'global_steps': 167, 'epoch': 1, 'steps': 25}\n","{'loss/train': 1.0881009101867676, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 168, 'epoch': 1, 'steps': 26}\n","{'loss/train': 1.037341833114624, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 169, 'epoch': 1, 'steps': 27}\n","{'loss/train': 1.1008368730545044, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 170, 'epoch': 1, 'steps': 28}\n","{'loss/train': 1.6423226594924927, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 171, 'epoch': 1, 'steps': 29}\n","{'loss/train': 1.412522315979004, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 172, 'epoch': 1, 'steps': 30}\n","{'loss/train': 1.3586280345916748, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 173, 'epoch': 1, 'steps': 31}\n","{'loss/train': 1.1082040071487427, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 174, 'epoch': 1, 'steps': 32}\n","{'loss/train': 1.1589374542236328, 'completed_steps': 21, 'lr': [0.00017239436619718307, 0.00017239436619718307], 'global_steps': 175, 'epoch': 1, 'steps': 33}\n","{'loss/train': 1.0077686309814453, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 176, 'epoch': 1, 'steps': 34}\n","{'loss/train': 1.1995716094970703, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 177, 'epoch': 1, 'steps': 35}\n","{'loss/train': 1.0377784967422485, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 178, 'epoch': 1, 'steps': 36}\n","{'loss/train': 1.0578291416168213, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 179, 'epoch': 1, 'steps': 37}\n","{'loss/train': 1.6060175895690918, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 180, 'epoch': 1, 'steps': 38}\n","{'loss/train': 1.1973528861999512, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 181, 'epoch': 1, 'steps': 39}\n","{'loss/train': 1.1987155675888062, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 182, 'epoch': 1, 'steps': 40}\n","{'loss/train': 1.1626659631729126, 'completed_steps': 22, 'lr': [0.00016985915492957746, 0.00016985915492957746], 'global_steps': 183, 'epoch': 1, 'steps': 41}\n","{'loss/train': 0.9521509408950806, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 184, 'epoch': 1, 'steps': 42}\n","{'loss/train': 1.5352504253387451, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 185, 'epoch': 1, 'steps': 43}\n","{'loss/train': 1.044122338294983, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 186, 'epoch': 1, 'steps': 44}\n","{'loss/train': 1.3173686265945435, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 187, 'epoch': 1, 'steps': 45}\n","{'loss/train': 0.8696577548980713, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 188, 'epoch': 1, 'steps': 46}\n","{'loss/train': 1.2389187812805176, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 189, 'epoch': 1, 'steps': 47}\n","{'loss/train': 1.2835832834243774, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 190, 'epoch': 1, 'steps': 48}\n","{'loss/train': 1.1655501127243042, 'completed_steps': 23, 'lr': [0.00016732394366197182, 0.00016732394366197182], 'global_steps': 191, 'epoch': 1, 'steps': 49}\n","{'loss/eval': 1.6044015884399414, 'perplexity': 4.974881649017334, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 192, 'epoch': 1, 'steps': 49, 'loss/train': 1.1655501127243042}\n"]},{"output_type":"stream","name":"stderr","text":["Several commits (4) will be pushed upstream.\n","WARNING:huggingface_hub.repository:Several commits (4) will be pushed upstream.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["{'loss/train': 1.1094627380371094, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 192, 'epoch': 1, 'steps': 50}\n","{'loss/train': 1.1844112873077393, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 193, 'epoch': 1, 'steps': 51}\n","{'loss/train': 1.0569342374801636, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 194, 'epoch': 1, 'steps': 52}\n","{'loss/train': 1.0430165529251099, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 195, 'epoch': 1, 'steps': 53}\n","{'loss/train': 1.265427589416504, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 196, 'epoch': 1, 'steps': 54}\n","{'loss/train': 1.712423324584961, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 197, 'epoch': 1, 'steps': 55}\n","{'loss/train': 1.3028028011322021, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 198, 'epoch': 1, 'steps': 56}\n","{'loss/train': 1.218639850616455, 'completed_steps': 24, 'lr': [0.00016478873239436618, 0.00016478873239436618], 'global_steps': 199, 'epoch': 1, 'steps': 57}\n","{'loss/train': 1.276551365852356, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 200, 'epoch': 1, 'steps': 58}\n","{'loss/train': 0.9365878105163574, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 201, 'epoch': 1, 'steps': 59}\n","{'loss/train': 1.245631217956543, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 202, 'epoch': 1, 'steps': 60}\n","{'loss/train': 1.294215202331543, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 203, 'epoch': 1, 'steps': 61}\n","{'loss/train': 1.0140149593353271, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 204, 'epoch': 1, 'steps': 62}\n","{'loss/train': 1.040529489517212, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 205, 'epoch': 1, 'steps': 63}\n","{'loss/train': 1.3484740257263184, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 206, 'epoch': 1, 'steps': 64}\n","{'loss/train': 1.1434581279754639, 'completed_steps': 25, 'lr': [0.00016225352112676057, 0.00016225352112676057], 'global_steps': 207, 'epoch': 1, 'steps': 65}\n","{'loss/train': 1.1498870849609375, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 208, 'epoch': 1, 'steps': 66}\n","{'loss/train': 1.1106942892074585, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 209, 'epoch': 1, 'steps': 67}\n","{'loss/train': 1.0919184684753418, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 210, 'epoch': 1, 'steps': 68}\n","{'loss/train': 1.1712229251861572, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 211, 'epoch': 1, 'steps': 69}\n","{'loss/train': 1.2845059633255005, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 212, 'epoch': 1, 'steps': 70}\n","{'loss/train': 1.5855287313461304, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 213, 'epoch': 1, 'steps': 71}\n","{'loss/train': 0.7141705751419067, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 214, 'epoch': 1, 'steps': 72}\n","{'loss/train': 1.266813039779663, 'completed_steps': 26, 'lr': [0.00015971830985915493, 0.00015971830985915493], 'global_steps': 215, 'epoch': 1, 'steps': 73}\n","{'loss/train': 1.1894464492797852, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 216, 'epoch': 1, 'steps': 74}\n","{'loss/train': 1.2124745845794678, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 217, 'epoch': 1, 'steps': 75}\n","{'loss/train': 1.1380996704101562, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 218, 'epoch': 1, 'steps': 76}\n","{'loss/train': 1.0856871604919434, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 219, 'epoch': 1, 'steps': 77}\n","{'loss/train': 1.061909794807434, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 220, 'epoch': 1, 'steps': 78}\n","{'loss/train': 1.0611252784729004, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 221, 'epoch': 1, 'steps': 79}\n","{'loss/train': 1.4886829853057861, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 222, 'epoch': 1, 'steps': 80}\n","{'loss/train': 1.3710265159606934, 'completed_steps': 27, 'lr': [0.00015718309859154926, 0.00015718309859154926], 'global_steps': 223, 'epoch': 1, 'steps': 81}\n","{'loss/train': 1.0074033737182617, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 224, 'epoch': 1, 'steps': 82}\n","{'loss/train': 1.1363329887390137, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 225, 'epoch': 1, 'steps': 83}\n","{'loss/train': 1.0135705471038818, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 226, 'epoch': 1, 'steps': 84}\n","{'loss/train': 1.0224609375, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 227, 'epoch': 1, 'steps': 85}\n","{'loss/train': 1.171615481376648, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 228, 'epoch': 1, 'steps': 86}\n","{'loss/train': 1.0723323822021484, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 229, 'epoch': 1, 'steps': 87}\n","{'loss/train': 1.0541969537734985, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 230, 'epoch': 1, 'steps': 88}\n","{'loss/train': 1.13595712184906, 'completed_steps': 28, 'lr': [0.00015464788732394365, 0.00015464788732394365], 'global_steps': 231, 'epoch': 1, 'steps': 89}\n","{'loss/train': 1.208815574645996, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 232, 'epoch': 1, 'steps': 90}\n","{'loss/train': 1.0846428871154785, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 233, 'epoch': 1, 'steps': 91}\n","{'loss/train': 0.8334661722183228, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 234, 'epoch': 1, 'steps': 92}\n","{'loss/train': 1.3356565237045288, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 235, 'epoch': 1, 'steps': 93}\n","{'loss/train': 1.0009623765945435, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 236, 'epoch': 1, 'steps': 94}\n","{'loss/train': 1.0731384754180908, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 237, 'epoch': 1, 'steps': 95}\n","{'loss/train': 1.1921523809432983, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 238, 'epoch': 1, 'steps': 96}\n","{'loss/train': 1.0087666511535645, 'completed_steps': 29, 'lr': [0.000152112676056338, 0.000152112676056338], 'global_steps': 239, 'epoch': 1, 'steps': 97}\n","{'loss/eval': 1.594693899154663, 'perplexity': 4.926820755004883, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 240, 'epoch': 1, 'steps': 97, 'loss/train': 1.0087666511535645}\n"]},{"output_type":"stream","name":"stderr","text":["Several commits (5) will be pushed upstream.\n","WARNING:huggingface_hub.repository:Several commits (5) will be pushed upstream.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["{'loss/train': 0.9177290201187134, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 240, 'epoch': 1, 'steps': 98}\n","{'loss/train': 1.2045683860778809, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 241, 'epoch': 1, 'steps': 99}\n","{'loss/train': 1.3974401950836182, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 242, 'epoch': 1, 'steps': 100}\n","{'loss/train': 0.9510871171951294, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 243, 'epoch': 1, 'steps': 101}\n","{'loss/train': 1.313844919204712, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 244, 'epoch': 1, 'steps': 102}\n","{'loss/train': 0.9914324879646301, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 245, 'epoch': 1, 'steps': 103}\n","{'loss/train': 1.2167444229125977, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 246, 'epoch': 1, 'steps': 104}\n","{'loss/train': 1.0264005661010742, 'completed_steps': 30, 'lr': [0.00014957746478873237, 0.00014957746478873237], 'global_steps': 247, 'epoch': 1, 'steps': 105}\n","{'loss/train': 1.1128888130187988, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 248, 'epoch': 1, 'steps': 106}\n","{'loss/train': 0.8803284168243408, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 249, 'epoch': 1, 'steps': 107}\n","{'loss/train': 1.2145520448684692, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 250, 'epoch': 1, 'steps': 108}\n","{'loss/train': 1.0095194578170776, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 251, 'epoch': 1, 'steps': 109}\n","{'loss/train': 1.2442641258239746, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 252, 'epoch': 1, 'steps': 110}\n","{'loss/train': 1.0686836242675781, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 253, 'epoch': 1, 'steps': 111}\n","{'loss/train': 1.168726921081543, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 254, 'epoch': 1, 'steps': 112}\n","{'loss/train': 1.0367997884750366, 'completed_steps': 31, 'lr': [0.00014704225352112676, 0.00014704225352112676], 'global_steps': 255, 'epoch': 1, 'steps': 113}\n","{'loss/train': 0.8753907680511475, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 256, 'epoch': 1, 'steps': 114}\n","{'loss/train': 0.9968842267990112, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 257, 'epoch': 1, 'steps': 115}\n","{'loss/train': 1.4947015047073364, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 258, 'epoch': 1, 'steps': 116}\n","{'loss/train': 1.1707987785339355, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 259, 'epoch': 1, 'steps': 117}\n","{'loss/train': 1.6016587018966675, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 260, 'epoch': 1, 'steps': 118}\n","{'loss/train': 0.9928982853889465, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 261, 'epoch': 1, 'steps': 119}\n","{'loss/train': 1.2534831762313843, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 262, 'epoch': 1, 'steps': 120}\n","{'loss/train': 0.7898895740509033, 'completed_steps': 32, 'lr': [0.00014450704225352112, 0.00014450704225352112], 'global_steps': 263, 'epoch': 1, 'steps': 121}\n","{'loss/train': 1.1299105882644653, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 264, 'epoch': 1, 'steps': 122}\n","{'loss/train': 1.06374192237854, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 265, 'epoch': 1, 'steps': 123}\n","{'loss/train': 1.6832606792449951, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 266, 'epoch': 1, 'steps': 124}\n","{'loss/train': 1.085900902748108, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 267, 'epoch': 1, 'steps': 125}\n","{'loss/train': 1.303304672241211, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 268, 'epoch': 1, 'steps': 126}\n","{'loss/train': 0.9882407188415527, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 269, 'epoch': 1, 'steps': 127}\n","{'loss/train': 1.3325828313827515, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 270, 'epoch': 1, 'steps': 128}\n","{'loss/train': 1.2289519309997559, 'completed_steps': 33, 'lr': [0.00014197183098591548, 0.00014197183098591548], 'global_steps': 271, 'epoch': 1, 'steps': 129}\n","{'loss/train': 1.5627962350845337, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 272, 'epoch': 1, 'steps': 130}\n","{'loss/train': 1.7209460735321045, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 273, 'epoch': 1, 'steps': 131}\n","{'loss/train': 1.4459574222564697, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 274, 'epoch': 1, 'steps': 132}\n","{'loss/train': 1.0227642059326172, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 275, 'epoch': 1, 'steps': 133}\n","{'loss/train': 1.2346901893615723, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 276, 'epoch': 1, 'steps': 134}\n","{'loss/train': 1.155513048171997, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 277, 'epoch': 1, 'steps': 135}\n","{'loss/train': 0.8159679174423218, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 278, 'epoch': 1, 'steps': 136}\n","{'loss/train': 0.949541449546814, 'completed_steps': 34, 'lr': [0.00013943661971830984, 0.00013943661971830984], 'global_steps': 279, 'epoch': 1, 'steps': 137}\n","{'loss/train': 1.1126660108566284, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 280, 'epoch': 1, 'steps': 138}\n","{'loss/train': 1.3234844207763672, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 281, 'epoch': 1, 'steps': 139}\n","{'loss/train': 1.043034315109253, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 282, 'epoch': 1, 'steps': 140}\n","{'loss/train': 1.4261304140090942, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 283, 'epoch': 1, 'steps': 141}\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/142 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be0647a47b2427b96cb35b0738565c6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'loss/train': 1.2128849029541016, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 284, 'epoch': 2, 'steps': 0}\n","{'loss/train': 1.123058557510376, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 285, 'epoch': 2, 'steps': 1}\n","{'loss/train': 0.9079849720001221, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 286, 'epoch': 2, 'steps': 2}\n","{'loss/train': 1.1306798458099365, 'completed_steps': 35, 'lr': [0.0001369014084507042, 0.0001369014084507042], 'global_steps': 287, 'epoch': 2, 'steps': 3}\n","{'loss/eval': 1.5977909564971924, 'perplexity': 4.942102909088135, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 288, 'epoch': 2, 'steps': 3, 'loss/train': 1.1306798458099365}\n"]},{"output_type":"stream","name":"stderr","text":["Several commits (6) will be pushed upstream.\n","WARNING:huggingface_hub.repository:Several commits (6) will be pushed upstream.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["{'loss/train': 0.9049314856529236, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 288, 'epoch': 2, 'steps': 4}\n","{'loss/train': 0.870507538318634, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 289, 'epoch': 2, 'steps': 5}\n","{'loss/train': 1.0990574359893799, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 290, 'epoch': 2, 'steps': 6}\n","{'loss/train': 1.1245577335357666, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 291, 'epoch': 2, 'steps': 7}\n","{'loss/train': 1.3111896514892578, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 292, 'epoch': 2, 'steps': 8}\n","{'loss/train': 0.7982566952705383, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 293, 'epoch': 2, 'steps': 9}\n","{'loss/train': 1.2051491737365723, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 294, 'epoch': 2, 'steps': 10}\n","{'loss/train': 0.9697302579879761, 'completed_steps': 36, 'lr': [0.0001343661971830986, 0.0001343661971830986], 'global_steps': 295, 'epoch': 2, 'steps': 11}\n","{'loss/train': 1.08732008934021, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 296, 'epoch': 2, 'steps': 12}\n","{'loss/train': 0.8284153938293457, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 297, 'epoch': 2, 'steps': 13}\n","{'loss/train': 1.3208043575286865, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 298, 'epoch': 2, 'steps': 14}\n","{'loss/train': 1.0661311149597168, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 299, 'epoch': 2, 'steps': 15}\n","{'loss/train': 1.0073164701461792, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 300, 'epoch': 2, 'steps': 16}\n","{'loss/train': 1.0887949466705322, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 301, 'epoch': 2, 'steps': 17}\n","{'loss/train': 1.1280053853988647, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 302, 'epoch': 2, 'steps': 18}\n","{'loss/train': 1.115919828414917, 'completed_steps': 37, 'lr': [0.00013183098591549295, 0.00013183098591549295], 'global_steps': 303, 'epoch': 2, 'steps': 19}\n","{'loss/train': 0.9975685477256775, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 304, 'epoch': 2, 'steps': 20}\n","{'loss/train': 0.917283833026886, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 305, 'epoch': 2, 'steps': 21}\n","{'loss/train': 1.011915922164917, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 306, 'epoch': 2, 'steps': 22}\n","{'loss/train': 0.8263821601867676, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 307, 'epoch': 2, 'steps': 23}\n","{'loss/train': 0.9673077464103699, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 308, 'epoch': 2, 'steps': 24}\n","{'loss/train': 1.1162335872650146, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 309, 'epoch': 2, 'steps': 25}\n","{'loss/train': 1.0609939098358154, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 310, 'epoch': 2, 'steps': 26}\n","{'loss/train': 0.9780042171478271, 'completed_steps': 38, 'lr': [0.00012929577464788731, 0.00012929577464788731], 'global_steps': 311, 'epoch': 2, 'steps': 27}\n","{'loss/train': 0.7570791840553284, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 312, 'epoch': 2, 'steps': 28}\n","{'loss/train': 1.041785717010498, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 313, 'epoch': 2, 'steps': 29}\n","{'loss/train': 0.9284307360649109, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 314, 'epoch': 2, 'steps': 30}\n","{'loss/train': 1.0569355487823486, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 315, 'epoch': 2, 'steps': 31}\n","{'loss/train': 1.0306353569030762, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 316, 'epoch': 2, 'steps': 32}\n","{'loss/train': 0.9522996544837952, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 317, 'epoch': 2, 'steps': 33}\n","{'loss/train': 1.2066676616668701, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 318, 'epoch': 2, 'steps': 34}\n","{'loss/train': 1.1205929517745972, 'completed_steps': 39, 'lr': [0.00012676056338028168, 0.00012676056338028168], 'global_steps': 319, 'epoch': 2, 'steps': 35}\n","{'loss/train': 0.6751864552497864, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 320, 'epoch': 2, 'steps': 36}\n","{'loss/train': 0.8419250249862671, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 321, 'epoch': 2, 'steps': 37}\n","{'loss/train': 1.0745069980621338, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 322, 'epoch': 2, 'steps': 38}\n","{'loss/train': 1.0436429977416992, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 323, 'epoch': 2, 'steps': 39}\n","{'loss/train': 1.3237227201461792, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 324, 'epoch': 2, 'steps': 40}\n","{'loss/train': 1.1536474227905273, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 325, 'epoch': 2, 'steps': 41}\n","{'loss/train': 0.8878151774406433, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 326, 'epoch': 2, 'steps': 42}\n","{'loss/train': 1.1734161376953125, 'completed_steps': 40, 'lr': [0.00012422535211267604, 0.00012422535211267604], 'global_steps': 327, 'epoch': 2, 'steps': 43}\n","{'loss/train': 0.980623722076416, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 328, 'epoch': 2, 'steps': 44}\n","{'loss/train': 0.9852340221405029, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 329, 'epoch': 2, 'steps': 45}\n","{'loss/train': 1.0383071899414062, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 330, 'epoch': 2, 'steps': 46}\n","{'loss/train': 0.9396648406982422, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 331, 'epoch': 2, 'steps': 47}\n","{'loss/train': 0.9137988686561584, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 332, 'epoch': 2, 'steps': 48}\n","{'loss/train': 0.7982299327850342, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 333, 'epoch': 2, 'steps': 49}\n","{'loss/train': 0.7437149286270142, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 334, 'epoch': 2, 'steps': 50}\n","{'loss/train': 0.7411555051803589, 'completed_steps': 41, 'lr': [0.00012169014084507041, 0.00012169014084507041], 'global_steps': 335, 'epoch': 2, 'steps': 51}\n","{'loss/eval': 1.5951077938079834, 'perplexity': 4.928860187530518, 'completed_steps': 42, 'lr': [0.00011915492957746479, 0.00011915492957746479], 'global_steps': 336, 'epoch': 2, 'steps': 51, 'loss/train': 0.7411555051803589}\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-cb57008ab99a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpush_to_hub\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     repo.push_to_hub(\n\u001b[0m\u001b[1;32m     60\u001b[0m                         \u001b[0mcommit_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0mTraining\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompleted_steps\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcompleted_steps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mglobal_steps\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mglobal_steps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                          \u001b[0mepoch\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \"\"\"\n\u001b[0;32m-> 1319\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclean_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_repo_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Repo currently clean. Ignoring push_to_hub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mis_repo_clean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \"\"\"\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0mgit_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_subprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"git status --porcelain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_subprocess.py\u001b[0m in \u001b[0;36mrun_subprocess\u001b[0;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     return subprocess.run(\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","add_to_tensorboard(drive_train_res_path, tensorboard_run_path)"],"metadata":{"id":"fuzcHch1MWt3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir \"{tensorboard_run_path}\""],"metadata":{"id":"ccAmPDh7pwaI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TESTING PRETRAINED MODEL"],"metadata":{"id":"9vi6XSOUTtO8"}},{"cell_type":"code","source":["coq_model = GPT2LMHeadModel.from_pretrained(\"Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train\")\n","coq_tokenizer = AutoTokenizer.from_pretrained(\"Andrusyshyn/gpt2-coq-tokenizer\")\n","pipe = pipeline(\n","    \"text-generation\", model=coq_model, tokenizer=coq_tokenizer#, device=0\n",")"],"metadata":{"id":"IU005nHITxB5","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"error","timestamp":1708957870721,"user_tz":-120,"elapsed":1639,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"80c3b34e-f2b2-4022-a2e3-af061bafcbee"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-5687d943fba1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcoq_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Andrusyshyn/gpt2-coq-tokenizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m pipe = pipeline(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoq_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoq_tokenizer\u001b[0m\u001b[0;31m#, device=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3848\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3849\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3850\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3851\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3852\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   4223\u001b[0m                 \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4224\u001b[0m             )\n\u001b[0;32m-> 4225\u001b[0;31m             \u001b[0merror_msgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_state_dict_into_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4226\u001b[0m             \u001b[0moffload_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;31m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;31m# it's safe to delete it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    619\u001b[0m                             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                     error_msgs.append(f'While copying the parameter named \"{key}\", '\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model = coq_model\n","evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"yGFokRO3IEOc","executionInfo":{"status":"error","timestamp":1707425966044,"user_tz":-120,"elapsed":6182381,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"b36206a2-74c2-491f-a8c0-3b33a8d0e2b5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c9e222b9a73f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoq_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-fed43d284866>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# print(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(outputs.loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(accelerator.gather(outputs.loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0;31m# Flatten the tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["txt = \"\"\"Theorem identity : forall (n : nat), n = n.\"\"\"\n","print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rd1khsdT66h","executionInfo":{"status":"ok","timestamp":1707121104711,"user_tz":-120,"elapsed":3176,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"96bf82d5-3d0c-4135-e623-881d08216c96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Theorem identity : forall (n : nat), n = n.\n","intros; red; intros; destruct n; simpl; auto.\n","Qed.\n","\n","Theorem eq_sym : forall X : Ens, IN X X H.\n","intros;\n"]}]},{"cell_type":"markdown","source":["### SANDBOX"],"metadata":{"id":"_srRfnAxr_cG"}},{"cell_type":"code","source":["class CustomStoppingCriteria(StoppingCriteria):\n","    def __init__(self, stop_sequences):\n","        super().__init__()\n","        self.stop_sequences = stop_sequences\n","\n","    def __call__(self, input_ids, scores, **kwargs):\n","        # print(input_ids)\n","        # Check if the generated text ends with any of the stop sequences\n","        for sequence in self.stop_sequences:\n","            subsequence = input_ids[0][-len(sequence):]\n","            # print(\"###############################################################\")\n","            # print(sequence, subsequence)\n","            if (sequence == subsequence.tolist()):\n","                # print(\"RETURN TRUEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\")\n","                return True  # Stop criteria met\n","        return False  # Stop criteria not met"],"metadata":{"id":"uIOwx6pE1RFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# stop_sequences = [['ĠQed', '.'], ['Qed', '.']]  # Example stop sequences\n","stop_sequences = [[372, 14]]\n","custom_stopping_criteria = CustomStoppingCriteria(stop_sequences)\n","stopping_criteria = StoppingCriteriaList([custom_stopping_criteria])"],"metadata":{"id":"SdauXZsT1TUn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for stop_seq in stop_sequences:\n","  print(tokenizer.encode(stop_seq))"],"metadata":{"id":"-SQLTM2T2wWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenizer.encode('ĠQed'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlL0OaD62-oI","executionInfo":{"status":"ok","timestamp":1708958426648,"user_tz":-120,"elapsed":2,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"ede025b4-cc54-4796-e585-da9d5c1b338b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[129, 255, 372]\n"]}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"Andrusyshyn/gpt2-coq-tokenizer\")\n","model = GPT2LMHeadModel.from_pretrained(\"Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train\")\n","pipe = pipeline(\n","    \"text-generation\", model=model, tokenizer=tokenizer, stopping_criteria=stopping_criteria#, device=0\n",")"],"metadata":{"id":"oCOQ4GMQsDL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate text\n","generated_text = pipe([\"Theorem theorem1 : forall (n : nat), n + 0 = n.\"], num_return_sequences=50)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGPCjKzs1Vwu","executionInfo":{"status":"ok","timestamp":1708960585029,"user_tz":-120,"elapsed":19167,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"90fcb798-226d-49ad-d865-30a19411d964"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nauto with arith.\\nQed.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nHint Immediate plus_reg_l: arith.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  induction n as IHn as [ |'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; case n; auto'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* QuickChick plus_n_O.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; rewrite mult_comm.\\nrewrite'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto.\\nQed'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintros. omega.\\nQed.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro n; case n; auto.\\nsimpl'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nQed.\\n\\nTheorem plus_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\nAxiom mult_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro; omega.\\nQed.\\n\\nLemma'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\ntauto.\\nQed.\\n\\nTheorem le_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros; omega.\\nQed.\\n\\nTheorem'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto.\\nintros'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.\\nHint Resolve'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto.\\nQed'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  assert (H := le_plus'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.\\nHint Resolve'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintros n; rewrite (plus_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro n.\\napply (Build_Map ('}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* OUT+1 n = n *)'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.\\nHint Resolve'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\n\\n  split.\\n  generalize n.\\n  clear n.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro; apply (le_Sn_O n'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto.\\nQed.\\nHint Resolve is_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\n\\nTheorem mult'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  intro; cut (forall q rr'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\n\\nSection NPeano'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.\\nHint Resolve'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\napply (f_equal2 plus'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith. Qed.\\n\\nLemma mult'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nsimpl; auto.\\nQed.\\nHint Resolve'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto.\\nQed'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nreflexivity.\\nQed.\\n\\n\\n\\n\\nLemma mult_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintros n; rewrite <- (plus'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  intros n; apply n.\\n'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; apply le_plus'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto with arith.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; elim n; trivial'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\ncongruence.\\nQed.\\n\\nTheorem mult_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.\\n \\nTheorem'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro.\\nsymmetry.\\nrewrite H in H'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* (* numTests 11 *)\\n\\n'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; rewrite (plus_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintros n; simpl; omega.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* QuickChick plus_0_r.'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; apply (K_'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nHint Unfold minus.\\n\\nintro.\\nAdmitted'}, {'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro.\\nnow rewrite (plus'}]]\n"]}]},{"cell_type":"code","source":["for _ in range(50):\n","  generated_text = pipe([\"Theorem theorem1 : forall (n : nat), n + 0 = n.\"], num_return_sequences=1)\n","  print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAHTELCe-1Nc","executionInfo":{"status":"ok","timestamp":1708960715593,"user_tz":-120,"elapsed":116898,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"84532eef-202d-4d71-febe-cfca199ad63c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; unfold O in |- *; auto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nsimpl in |- *; auto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': \"Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; case n; simpl in |- *; auto.\\nintros n1 H'; right;\\nrewrite H'; auto.\\nunfold nat_of_P\"}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted.\\n\\nTheorem G1 : forall n m, n = m + m.\\nAdmitted. (* Leo: OUT-OFne *)\\n\\nTheorem G'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAbort.\\n\\nGoal forall (n m : nat), n + m + m = n + m.\\nintros; omega.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\n\\nDefinition O_total_order_T : forall n, {n=O}+{n<>O}.\\nShow. (*'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  induction n; auto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; rewrite (plus_comm n 0); apply mult_n_Sm.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n.\\nsimpl in |- *; auto with arith.\\nsimpl in |- *.\\nintro; apply le_O_n.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; now rewrite one_succ, IHn, add_0_l.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\n  intros; pattern n at 1 in |- *; rewrite mult_1_r; ring.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro.\\nring.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintros n; unfold le.\\napply plus_O.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro; case n; auto with arith.\\nintros n0; case n0; auto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\ninduction n.\\nnow simpl.\\nintros ; rewrite IHn ; clear IHn ; easy.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof (fun n => n + n <= n).\\nintro; rewrite (plus_comm n (0 + n)); rewrite (plus_assoc n ( n'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nsimpl; auto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nunfold plus; auto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\n  simpl; intuition;\\n  rewrite (expnat_1 n); rewrite expnat_0;\\n  auto.\\n  f_equal; omega.\\n  eapply IHn.\\n  omega'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': \"Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; simpl in |- *; auto.\\nintros n' H'1; apply le_plus_minus; auto.\\nQed.\"}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintros n; apply eq_nat_dec.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  eexists.\\n  trivial.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\n\\nTheorem mult_0_l : forall n, n * n = 0.\\nAdmitted. (* QuickChick mult_0_'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': \"Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto with arith.\\nintros n0 H'.\\ncut (n0 <= n + m0); auto with arith; intros n\"}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\nTheorem mult_comm : forall n m, n * m = m * m.\\nAdmitted. (* Higher Order *)\\n\\n'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted. (* Higher Order *)\\n\\nTheorem mult_plus_distr_l : forall (x y z : nat), x * (y * z) ='}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': \"Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; generalize dependent n.\\nelim (mult_sym n); simpl in |- *; auto with arith.\\nintros n1 H'; rewrite H'.\\n\"}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; elim n; simpl in |- *; auto.\\nintros n1 IH; case (Lt.le_or_lt n1 n'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro n; rewrite (mult_comm n 0); apply (p (S n)); auto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  (* We could use [group_zero], instead of building an\\n   equality, but is too to\\n   replace that n with (m + n'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro; apply (mult_eq (S n) (0 + n)).\\nrewrite plus_comm; rewrite H.\\nrepeat rewrite (plus_comm n'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n   intros n; rewrite even_mul; apply even_div_even.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro.\\ninduction n as [| n Hrecn].\\nsimpl in |- *.\\ntrivial.\\nsimpl in |- *.\\nrewrite Hrecn0.\\napply'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto with arith.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': \"Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintros n; elim n; auto with arith.\\nsimpl in |- *; auto with arith.\\nintros n0 H'; left; auto with arith.\\napply\"}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\ntauto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintuition.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  intro n; apply n_Sn.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\nintro; rewrite <- Nat.add_plus_distr_r.\\nsymmetry.\\napply mult_le_compat;Qed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nAdmitted.\\n\\nLemma foo : forall (n : nat), n = n.\\nAdmitted.\\n\\nGoal exists (A : nat -> Set), A ->'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\ninduction n with\\n| 0 => idtac\\n| false => auto with arith\\nend.\\nintros n v; case v; simpl.\\nintros'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nauto.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  induction n; simpl; trivial.\\n  destruct 1; trivial.\\n  rewrite IHn.\\n  rewrite IHn.\\n  trivial.\\nQed.'}]]\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nintro n. \\nsymmetry  in |- *. \\napply mult_le_compat_l.\\napply le_plus_minus.\\ninstantiate (1'}]]\n","[[{'generated_text': 'Theorem theorem1 : forall (n : nat), n + 0 = n.\\nProof.\\n  intro n.\\n  rewrite (plus_comm n).\\n  apply plus_le_compat.\\n  cset (plus (fact n) n); rewrite'}]]\n"]}]},{"cell_type":"code","source":["text = \"\"\"Theorem theorem1 : forall (n : nat), n + 0 = n.\n","\n","    intuition.\n","    eapply H.\n","    trivial.\n","    Qed.\"\"\"\n","\n","tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)\n","\n","# text = \"\"\"Theorem theorem1 : forall (n : nat), n + 0 = n.\n","# Proof.\n","#    apply eq_refl.\n","# Qed.\"\"\"\n","# #p_tokenizer(sample[\"content\"], truncation=False)[\"input_ids\"]\n","# tokenized_text = tokenizer.tokenize(text)\n","# print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbUl9TuxsYxt","executionInfo":{"status":"ok","timestamp":1708957358155,"user_tz":-120,"elapsed":282,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"c6d4fd63-303e-4b70-eef1-2c3f2d635b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Theorem', 'Ġtheorem', '1', 'Ġ:', 'Ġforall', 'Ġ(', 'n', 'Ġ:', 'Ġnat', '),', 'Ġn', 'Ġ+', 'Ġ0', 'Ġ=', 'Ġn', '.', 'ĊĠĠĠĠĊĠĠĠ', 'Ġintuition', '.', 'ĊĠĠĠ', 'Ġeapply', 'ĠH', '.', 'ĊĠĠĠ', 'Ġtrivial', '.', 'ĊĠĠĠ', 'ĠQed', '.']\n"]}]},{"cell_type":"code","source":["text = \"\"\"Theorem theorem1 : forall (n : nat), n + 0 = n.\n","\n","    intuition.\n","    eapply H.\n","    trivial.\n","    Qed.\"\"\"\n","input_ids = tokenizer(text, truncation=False)[\"input_ids\"][-2:]\n","print(input_ids)\n","print(tokenizer.decode(input_ids, skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2DwmcPEybD_","executionInfo":{"status":"ok","timestamp":1708957385791,"user_tz":-120,"elapsed":267,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"3c47b362-5195-4e04-d3c1-b718f08a482b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[560, 14]\n"," Qed.\n"]}]},{"cell_type":"code","source":["print(tokenizer.decode(199) == '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmXMXtKZ6Izd","executionInfo":{"status":"ok","timestamp":1708959311184,"user_tz":-120,"elapsed":305,"user":{"displayName":"Орест Андрусишин","userId":"10340723015027986950"}},"outputId":"bd03d936-ccc4-4a4d-921c-6c22286a8964"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]}]}