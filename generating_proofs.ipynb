{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAstmePep_vQ"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "from transformers import AutoTokenizer, GPT2LMHeadModel, pipeline, AutoModel, AutoConfig\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "from google.colab import runtime"
      ],
      "metadata": {
        "id": "lPEL1iqyqKkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length                = 1024\n",
        "max_new_tokens                 = 256\n",
        "batch_size                     = 1\n",
        "proofs_per_theorem             = 50\n",
        "temperature                    = 1\n",
        "do_sample                      = True\n",
        "top_p                          = 0.95\n",
        "model_repo_name                = \"Andrusyshyn/gpt2-pretrained-for-coq-pt-custom-train\"\n",
        "model_commit_hash              = \"41d3d96b6b3d0a267bb09893b5f851d658234ad7\"\n",
        "\n",
        "drive_mounted                  = True\n",
        "drive_mounted_path             = \"/content/gdrive/\"\n",
        "# theorems_input_file            = drive_mounted_path + \"My Drive/UCU/diploma/theorems/test_theorems_trunc.json\"\n",
        "# theorems_output_file           = drive_mounted_path + \"My Drive/UCU/diploma/theorems/generated_test_proofs.json\"\n",
        "theorems_input_file =          = drive_mounted_path + \"My Drive/UCU/diploma/theorems/test_theorems_trunc.json\"\n",
        "theorems_output_file           = drive_mounted_path + \"My Drive/UCU/diploma/theorems/generated_test_theorems_trunc.json\"\n",
        "\n",
        "do_test_loss                   = False\n",
        "test_batch_size                = 16\n",
        "test_data_archived             = True    # set to True if you need to unarchive the data\n",
        "raw_test_archive               = drive_mounted_path + \"My Drive/UCU/diploma/datasets/dataset_test.zip\"         # only needed if data_archived == True\n",
        "raw_test_json                  = \"./dataset_test.json\"       # only needed if data_archived == False\n",
        "\n",
        "torch_seed                     = 7\n",
        "torch.manual_seed(torch_seed)"
      ],
      "metadata": {
        "id": "MDt9V_0_r0XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780f98a9-5eb7-44e8-ee0a-c7b09f3900ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79c3302258d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CUSTOM LOSS FUNCTION\n",
        "def custom_loss(inputs, logits):\n",
        "    shifted_labels = inputs[..., 1:].contiguous()\n",
        "    shifted_logits = logits[..., :-1, :].contiguous()\n",
        "    loss_func = CrossEntropyLoss(reduction='none')\n",
        "    loss = loss_func(shifted_logits.view(-1, shifted_logits.size(-1)), shifted_labels.view(-1))\n",
        "    loss_per_sequence = loss.view(shifted_logits.size(0), shifted_logits.size(1)).mean(axis=1)\n",
        "    return loss_per_sequence.mean()"
      ],
      "metadata": {
        "id": "cvV9Heee4HYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS EVALUATION FUNCTION\n",
        "def test_loss(p_model, p_test_dataloader, p_device):\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    p_model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(p_test_dataloader):\n",
        "            with torch.no_grad():\n",
        "                input_ids = batch[\"input_ids\"].to(p_device)\n",
        "                logits = p_model(input_ids).logits\n",
        "                loss = custom_loss(input_ids, logits)\n",
        "                losses.append(loss.item())\n",
        "    loss = torch.mean(torch.Tensor(losses))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss)\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return loss.item(), perplexity.item()"
      ],
      "metadata": {
        "id": "R7pWkTT55dB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TOKENIZE RAW DATASET\n",
        "def get_tokenized_dataset(p_raw_dataset, p_context_length, p_tokenizer):\n",
        "    concatenated_tokenized_samples = []\n",
        "    for sample in p_raw_dataset:\n",
        "        tokenized_sample = p_tokenizer(sample[\"content\"], truncation=False)[\"input_ids\"]\n",
        "        concatenated_tokenized_samples.extend(tokenized_sample + [p_tokenizer.eos_token_id])\n",
        "\n",
        "    tokenized_dataset_list = []\n",
        "    for i in range(0, len(concatenated_tokenized_samples), p_context_length):\n",
        "        input_ids = concatenated_tokenized_samples[i : i + p_context_length]\n",
        "        if len(input_ids) == p_context_length:\n",
        "            tokenized_dataset_list.append(torch.tensor(input_ids))\n",
        "\n",
        "    return Dataset.from_dict({\"input_ids\": tokenized_dataset_list})"
      ],
      "metadata": {
        "id": "orRR7rXZ0GWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRACT THEOREM STATEMENT FROM WHOLE PROOF\n",
        "def extract_theorem_statement(theorem_with_proof):\n",
        "    pos = theorem_with_proof.find(\"\\nProof.\")\n",
        "    if pos != -1:\n",
        "        return theorem_with_proof[:pos]\n",
        "\n",
        "    print(\"THEOREM PROOF DOES NOT START WITH 'Proof.'\")\n",
        "    return theorem_with_proof"
      ],
      "metadata": {
        "id": "77PpCyp8s7Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRUNCATE PROOF TILL STOP WORD\n",
        "def truncate_on_Qed(generated_proof: str):\n",
        "    qed_stop = \"Qed.\"\n",
        "    defined_stop = \"Defined.\"\n",
        "    save_stop = \"Save\"\n",
        "\n",
        "    pos_qed = generated_proof.find(qed_stop)\n",
        "    pos_defined = generated_proof.find(defined_stop)\n",
        "    pos_save = generated_proof.find(save_stop)\n",
        "\n",
        "    poses_stops = []\n",
        "    if (pos_qed != -1):\n",
        "        poses_stops.append(pos_qed)\n",
        "    if (pos_defined != -1):\n",
        "        poses_stops.append(pos_defined)\n",
        "    if (pos_save != -1):\n",
        "        poses_stops.append(pos_save)\n",
        "    if (poses_stops == []):\n",
        "        return (generated_proof, False)\n",
        "\n",
        "    return (generated_proof[:min(poses_stops)], True)"
      ],
      "metadata": {
        "id": "kv8VXRuNwMDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROOF GENERATION\n",
        "def generate_proofs(input_file, output_file, p_pipe, num_proofs):\n",
        "    new_json_data = None\n",
        "    with open(input_file, mode='r') as json_input:\n",
        "        new_json_data = json.load(json_input)\n",
        "\n",
        "    theorems_processed = 0\n",
        "    proofs_with_end = 0\n",
        "    for project in new_json_data[\"projects\"].keys():\n",
        "        for i in range(0, len(new_json_data[\"projects\"][project]), batch_size):\n",
        "            theorems = new_json_data[\"projects\"][project][i:i+batch_size]\n",
        "            input_sequences = []\n",
        "            theorem_declarations = []\n",
        "            for theorem in theorems:\n",
        "                theorem_declaration = extract_theorem_statement(theorem[\"proof\"])\n",
        "                theorem_declarations.append(theorem_declaration)\n",
        "                input_sequence = theorem[\"context\"] + theorem_declaration\n",
        "                input_sequences.append(input_sequence)\n",
        "\n",
        "            generated_texts = p_pipe(input_sequences, num_return_sequences=num_proofs,\n",
        "                                     max_new_tokens=max_new_tokens,\n",
        "                                     return_full_text=False,\n",
        "                                     do_sample=True, top_p=top_p, temperature=temperature)\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            ind = 0\n",
        "            for generated_text in generated_texts:\n",
        "                generated_proofs = []\n",
        "                for proof in generated_text:\n",
        "                    proof_with_no_context = theorem_declarations[ind] + proof['generated_text']\n",
        "                    truncated_proof, found_end = truncate_on_Qed(proof_with_no_context)\n",
        "                    if found_end:\n",
        "                        proofs_with_end += 1\n",
        "                    generated_proofs.append(truncated_proof + theorems[ind][\"end_command\"])\n",
        "                new_json_data[\"projects\"][project][ind+i][\"generated_proofs\"] = generated_proofs\n",
        "                theorems_processed += 1\n",
        "                ind += 1\n",
        "\n",
        "            if theorems_processed % 10 == 0:\n",
        "                print(theorems_processed)\n",
        "                with open(output_file, mode='w') as json_output:\n",
        "                    json.dump(new_json_data, json_output, indent=4)\n",
        "\n",
        "    with open(output_file, mode='w') as json_output:\n",
        "        json.dump(new_json_data, json_output, indent=4)\n",
        "    print(\"Theorems Processed: \", theorems_processed)\n",
        "    print(\"Proofs with end:    \", proofs_with_end)"
      ],
      "metadata": {
        "id": "KRM8oho9rLrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if drive_mounted:\n",
        "    drive.mount(drive_mounted_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpPZ3FCsuw55",
        "outputId": "5acae817-5dfa-4f6a-d24a-2d12bb97d091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNPACK DATASETS\n",
        "if do_test_loss:\n",
        "    if test_data_archived:\n",
        "        if raw_test_archive.endswith(\".gz\"):\n",
        "            !gzip -dkv \"{raw_test_archive}\"\n",
        "        if raw_test_archive.endswith(\".zip\"):\n",
        "            !unzip \"{raw_test_archive}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz5s04S30Qn3",
        "outputId": "1270e278-73c8-4b74-912f-aac7683b592a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/My Drive/UCU/diploma/datasets/dataset_test.zip\n",
            "replace dataset_test.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: dataset_test.json       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD TEST DATASET\n",
        "if do_test_loss:\n",
        "    raw_test_dataset = load_dataset(\"json\", data_files=raw_test_json, field=\"data\")\n",
        "    print(raw_test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhREingP0plT",
        "outputId": "424c4d42-f3d7-4b3b-e1f1-4062ce55afa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['content', 'filepath'],\n",
            "        num_rows: 953\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD MODEL AND TOKENIZER\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "coq_tokenizer = AutoTokenizer.from_pretrained(model_repo_name, revision=model_commit_hash)\n",
        "coq_model = GPT2LMHeadModel.from_pretrained(model_repo_name, revision=model_commit_hash).to(device)\n",
        "print(f\"Tokenizer vocab size:                              {len(coq_tokenizer)}\")\n",
        "print(f\"Model size:                                        {coq_model.num_parameters()}\")\n",
        "print(f\"Model size (only trainable params):                {coq_model.num_parameters(only_trainable=True)}\")\n",
        "print(f\"Model size (only trainable non-embeddings params): {coq_model.num_parameters(only_trainable=True, exclude_embeddings=True)}\")\n",
        "pipe = pipeline(\"text-generation\", model=coq_model, tokenizer=coq_tokenizer, batch_size=batch_size, device=0 if torch.cuda.is_available() else -1)\n",
        "pipe.tokenizer.pad_token_id = coq_model.config.eos_token_id\n",
        "pipe.tokenizer.padding_side = 'left'"
      ],
      "metadata": {
        "id": "hMJMbFUNqxOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45ff2d4-b28d-49c9-8039-b8d8cd928636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size:                              30000\n",
            "Model size:                                        108882432\n",
            "Model size (only trainable params):                108882432\n",
            "Model size (only trainable non-embeddings params): 85056000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if do_test_loss:\n",
        "    # TOKENIZE RAW DATASET\n",
        "    test_dataset = get_tokenized_dataset(raw_test_dataset[\"train\"], sequence_length, coq_tokenizer)\n",
        "    test_dataset.set_format(\"torch\")\n",
        "\n",
        "    # CREATE DATALOADER\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
        "    print(test_dataset)\n",
        "    print(\"len(test_dataloader): \", len(test_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELdcEjMq3DVY",
        "outputId": "279a6b5f-73f8-4e73-effc-2e9002ddefcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids'],\n",
            "    num_rows: 4068\n",
            "})\n",
            "len(test_dataloader):  255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE TEST LOSS\n",
        "if do_test_loss:\n",
        "    _loss,_perp = test_loss(coq_model, test_dataloader, device)\n",
        "    print(\"Test Loss:       \", _loss)\n",
        "    print(\"Test Perplexity: \", _perp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YleZJwx3Pzc",
        "outputId": "aecac454-f3a0-49bb-de8f-5699fb16bd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:        2.4030051231384277\n",
            "Test Perplexity:  11.056352615356445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROOF GENERATION\n",
        "generate_proofs(theorems_input_file, theorems_output_file, pipe, proofs_per_theorem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPSx0QqNqdkK",
        "outputId": "3600c6fb-0124-4383-aea7-4970ad88cb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theorems Processed:  434\n",
            "Proofs with end:     19884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "vInksapFK6lp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}