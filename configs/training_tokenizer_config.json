{
    "vocab_size"                   : 30000,
    "base_model"                   : "gpt2",
    "batch_size"                   : 20,

    "raw_train_json"               : "./datasets/dataset_train.json",

    "push_to_hub"                  : false,
    "tokenizer_repo_name"          : "Andrusyshyn/gpt2-coq-tokenizer",
    "tokenizer_output_dir"         : "gpt2-coq-tokenizer_local",
    "run_name"                     : "experimental"
}